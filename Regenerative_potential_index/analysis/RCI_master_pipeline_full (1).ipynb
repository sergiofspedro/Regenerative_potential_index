{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2661b9b5",
      "metadata": {
        "id": "2661b9b5"
      },
      "source": [
        "# Regenerative Potential Index — Master Pipeline\n",
        "\n",
        "## Table of Contents\n",
        "1. Setup  \n",
        "2. Original Code  \n",
        "3. Amsterdam District Processing (from manifest)  \n",
        "4. Map Visualisation (Amsterdam districts)  \n",
        "5. Histogram Generation per District  \n",
        "6. Radar Charts per District  \n",
        "7. Correlation Matrix of Indicators  \n",
        "8. Scenario Engine (one-step)  \n",
        "9. Time-Series Scenario Engine  \n",
        "10. Story-Based Scenarios  \n",
        "11. Plotly Dashboard Export (static for GitHub Pages)  \n",
        "12. GitHub Actions Builder (workflow + build script)  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1447eb28",
      "metadata": {
        "id": "1447eb28"
      },
      "source": [
        "# 1. Setup\n",
        "\n",
        "This section prepares the environment, imports packages and ensures the output folders exist.\n",
        "It is designed to work both locally and in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5d3837a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d3837a5",
        "outputId": "f669db5c-d3f7-4194-a0e6-39103dd71228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output folders: ['maps', 'histograms', 'scenarios', 'radar']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# Base output folders\n",
        "OUTPUT_DIR = \"RCI_outputs\"\n",
        "MAPS_DIR = os.path.join(OUTPUT_DIR, \"maps\")\n",
        "HIST_DIR = os.path.join(OUTPUT_DIR, \"histograms\")\n",
        "RADAR_DIR = os.path.join(OUTPUT_DIR, \"radar\")\n",
        "SCENARIO_DIR = os.path.join(OUTPUT_DIR, \"scenarios\")\n",
        "\n",
        "for d in [OUTPUT_DIR, MAPS_DIR, HIST_DIR, RADAR_DIR, SCENARIO_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "print(\"Output folders:\", os.listdir(OUTPUT_DIR))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "try:\n",
        "    import geopandas as gpd\n",
        "    import folium\n",
        "except ImportError:\n",
        "    print(\"geopandas/folium not installed. Install them if you want map visualisations.\")\n",
        "\n",
        "try:\n",
        "    import plotly.express as px\n",
        "except ImportError:\n",
        "    print(\"plotly not installed. Install it if you want the dashboard export.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d684e6f5",
      "metadata": {
        "id": "d684e6f5"
      },
      "source": [
        "# 2. Original Code\n",
        "\n",
        "This section contains your original RCI computation script, included verbatim."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0420f5a9",
      "metadata": {
        "id": "0420f5a9"
      },
      "source": [
        "## 2.1 Main RCI Script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc7193b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "cc7193b6",
        "outputId": "0f9f299c-a288-43c6-cf97-72f06a3fe094"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 404: Not Found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2211359683.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Load metadata (Excel) from GitHub raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMETADATA_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RCI_metadata.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0mneed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"indicator\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"pillar\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"direction\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneed_cols\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    631\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"# Regenerative Capacity Index — Colab (GitHub Raw, Pandas-only)\n",
        "\n",
        "This notebook loads your **metadata** and per-indicator **CSV time series** directly from **GitHub raw URLs** (no Google Drive mount, no DuckDB).\n",
        "It applies **5th–95th percentile normalization** (or your normative caps if provided), computes **pillar scores** and a **composite index** using **equal weights** and **geometric means**.\n",
        "\n",
        "## Repository structure (4-pillar folders)\n",
        "\n",
        "Place this structure in your GitHub repo:\n",
        "\n",
        "```\n",
        "RCI/\n",
        "├── data/\n",
        "│   ├── Environmental/           # e.g., pm25.csv, no2.csv, tree_canopy.csv\n",
        "│   ├── Economic/                # e.g., recycling_rate.csv, waste_per_capita.csv\n",
        "│   ├── Social/                  # e.g., participation_index.csv, greenspace_300m.csv\n",
        "│   └── Political/               # e.g., transparency_index.csv\n",
        "├── metadata/\n",
        "│   └── RCI_metadata_updated.xlsx\n",
        "├── manifests/\n",
        "│   └── values_manifest_github.csv   # indicator, relpath, year_col, value_col\n",
        "├── outputs/                      # created by Colab\n",
        "└── notebooks/\n",
        "    └── RCI_Colab_from_GitHub.ipynb\n",
        "```\n",
        "\n",
        "## 1) Configure your GitHub repo and paths\n",
        "\n",
        "- **BASE_URL** points to your repo's *raw* content (replace `<user>`, `<repo>`, `<branch>`).\n",
        "- **METADATA_URL** points to `metadata/RCI_metadata_updated.xlsx` in your repo.\n",
        "- **MANIFEST_URL** points to `manifests/values_manifest_github.csv`.\n",
        "\"\"\"\n",
        "\n",
        "# >>> EDIT THESE THREE LINES <<<\n",
        "USER   = \"<sergiofspedro>\"\n",
        "REPO   = \"<Regenerative_potential_index>\"\n",
        "BRANCH = \"main\"  # or 'master' or another branch name\n",
        "\n",
        "BASE_URL     = f\"https://raw.githubusercontent.com/{USER}/{REPO}/{BRANCH}\"\n",
        "METADATA_URL = f\"{BASE_URL}/tree/main/Regenerative_potential_index/metadata\"\n",
        "MANIFEST_URL = f\"{BASE_URL}/manifests/values_manifest_github.csv\"\n",
        "\n",
        "OUTPUT_XLSX  = \"RCI_outputs.xlsx\"  # Notebook will save this in Colab session; download or push to GitHub manually\n",
        "\n",
        "\"\"\"### Example: referencing a CSV within a pillar folder\n",
        "\n",
        "If your manifest has a row like:\n",
        "```\n",
        "indicator,relpath,year_col,value_col\n",
        "PM2.5 annual mean,data/Environmental/pm25.csv,year,value\n",
        "```\n",
        "\n",
        "Then the notebook will build the URL as:\n",
        "```\n",
        "https://raw.githubusercontent.com/<user>/<repo>/<branch>/data/Environmental/pm25.csv\n",
        "```\n",
        "and load it with `pd.read_csv(url)`.\n",
        "\n",
        "## 2) Load metadata and manifest from GitHub\n",
        "\n",
        "- **metadata** must include at least: `indicator`, `pillar`, `direction` (\"+\" or \"-\").\n",
        "- Optional `min_cap` and `max_cap` will override empirical 5th–95th caps.\n",
        "- **manifest** lists each indicator CSV **relative to the repo root** and the names of its year/value columns.\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load metadata (Excel) from GitHub raw\n",
        "meta = pd.read_excel(METADATA_URL, sheet_name=\"RCI_metadata.xlsx\")\n",
        "need_cols = {\"indicator\",\"pillar\",\"direction\"}\n",
        "missing = need_cols - set(meta.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"Metadata missing columns: {missing}\")\n",
        "meta[\"indicator\"] = meta[\"indicator\"].astype(str)\n",
        "meta[\"pillar\"]    = meta[\"pillar\"].astype(str)\n",
        "meta[\"direction\"] = meta[\"direction\"].astype(str).str.strip().replace({\"plus\":\"+\",\"minus\":\"-\"})\n",
        "\n",
        "for c in [\"min_cap\",\"max_cap\"]:\n",
        "    if c not in meta.columns:\n",
        "        meta[c] = \"\"\n",
        "\n",
        "# Load manifest (CSV) from GitHub raw\n",
        "man = pd.read_csv(MANIFEST_URL)\n",
        "need_cols = {\"indicator\",\"relpath\",\"year_col\",\"value_col\"}\n",
        "missing = need_cols - set(man.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"Manifest missing columns: {missing}\")\n",
        "man[\"indicator\"] = man[\"indicator\"].astype(str)\n",
        "\n",
        "\"\"\"## 3) Fetch indicator CSVs from GitHub and assemble values table\"\"\"\n",
        "\n",
        "frames = []\n",
        "for _, r in man.iterrows():\n",
        "    ind   = r[\"indicator\"]\n",
        "    rel   = r[\"relpath\"].lstrip(\"/\")\n",
        "    ycol  = r[\"year_col\"]\n",
        "    vcol  = r[\"value_col\"]\n",
        "    url   = f\"{BASE_URL}/{rel}\"\n",
        "    df_i  = pd.read_csv(url)\n",
        "    if ycol not in df_i.columns or vcol not in df_i.columns:\n",
        "        raise ValueError(f\"CSV {url} must contain columns '{ycol}' and '{vcol}'\")\n",
        "    sub = df_i[[ycol, vcol]].copy()\n",
        "    sub.columns = [\"year\",\"value\"]\n",
        "    sub[\"indicator\"] = ind\n",
        "    frames.append(sub)\n",
        "\n",
        "values = pd.concat(frames, ignore_index=True)\n",
        "values[\"year\"]  = pd.to_numeric(values[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
        "values[\"value\"] = pd.to_numeric(values[\"value\"], errors=\"coerce\")\n",
        "\n",
        "# Merge with metadata\n",
        "d = values.merge(meta, on=\"indicator\", how=\"left\")\n",
        "if d[\"direction\"].isna().any():\n",
        "    missing = d[d[\"direction\"].isna()][\"indicator\"].unique().tolist()\n",
        "    raise ValueError(f\"Indicators missing from metadata: {missing}\")\n",
        "\n",
        "\"\"\"## 4) Normalize (5th–95th per indicator unless overridden by metadata caps)\n",
        "- Direction: `+` higher is better, `-` lower is better.\n",
        "- If an indicator has few years, 5th–95th reduces to min–max; we add a small widening if needed.\n",
        "\"\"\"\n",
        "\n",
        "def caps_from_data(series: pd.Series):\n",
        "    s = pd.to_numeric(series, errors=\"coerce\").dropna()\n",
        "    if len(s) == 0:\n",
        "        return np.nan, np.nan\n",
        "    if len(s) < 10:\n",
        "        lo, hi = s.min(), s.max()\n",
        "    else:\n",
        "        lo, hi = s.quantile(0.05), s.quantile(0.95)\n",
        "    if not np.isfinite(lo) or not np.isfinite(hi) or lo == hi:\n",
        "        hi = (lo if np.isfinite(lo) else 0.0) + (abs(lo)*0.1 + 1e-6)\n",
        "    return lo, hi\n",
        "\n",
        "rows = []\n",
        "for ind, grp in d.groupby(\"indicator\"):\n",
        "    lo_meta = pd.to_numeric(grp[\"min_cap\"], errors=\"coerce\").dropna()\n",
        "    hi_meta = pd.to_numeric(grp[\"max_cap\"], errors=\"coerce\").dropna()\n",
        "    if len(lo_meta) and len(hi_meta):\n",
        "        lo, hi = float(lo_meta.iloc[0]), float(hi_meta.iloc[0])\n",
        "    else:\n",
        "        lo, hi = caps_from_data(grp[\"value\"])\n",
        "\n",
        "    g = grp.copy()\n",
        "    x = g[\"value\"].clip(lower=lo, upper=hi)\n",
        "    direction = (g[\"direction\"].iloc[0] or \"+\").strip()\n",
        "    if direction == \"-\":\n",
        "        score = (hi - x) / (hi - lo) * 100.0\n",
        "    else:\n",
        "        score = (x - lo) / (hi - lo) * 100.0\n",
        "\n",
        "    g[\"min_cap_used\"] = lo\n",
        "    g[\"max_cap_used\"] = hi\n",
        "    g[\"score_0_100\"]  = score.clip(lower=0, upper=100)\n",
        "    rows.append(g)\n",
        "\n",
        "scored = pd.concat(rows, ignore_index=True) if rows else d.copy()\n",
        "\n",
        "\"\"\"## 5) Aggregate to pillars and composite (equal weights, geometric mean)\"\"\"\n",
        "\n",
        "def geom_mean(series: pd.Series):\n",
        "    s = pd.to_numeric(series, errors=\"coerce\").dropna().clip(lower=1e-6)/100.0\n",
        "    if len(s)==0: return np.nan\n",
        "    return float(np.exp(np.mean(np.log(s))) * 100.0)\n",
        "\n",
        "pillar_rows = []\n",
        "for (year, pillar), grp in scored.groupby([\"year\",\"pillar\"], dropna=False):\n",
        "    ps = geom_mean(grp[\"score_0_100\"])\n",
        "    pillar_rows.append({\"year\":year, \"pillar\":pillar, \"pillar_score\":ps})\n",
        "pillars = pd.DataFrame(pillar_rows)\n",
        "\n",
        "comp_rows = []\n",
        "for year, grp in pillars.groupby(\"year\", dropna=False):\n",
        "    comp = geom_mean(grp[\"pillar_score\"])\n",
        "    comp_rows.append({\"year\":year, \"composite_score\":comp})\n",
        "composite = pd.DataFrame(comp_rows)\n",
        "\n",
        "\"\"\"## 6) Save outputs\"\"\"\n",
        "\n",
        "with pd.ExcelWriter(OUTPUT_XLSX) as w:\n",
        "    scored.to_excel(w, index=False, sheet_name=\"indicator_scores\")\n",
        "    pillars.to_excel(w, index=False, sheet_name=\"pillar_scores\")\n",
        "    composite.to_excel(w, index=False, sheet_name=\"composite_scores\")\n",
        "\n",
        "print(\"Saved:\", OUTPUT_XLSX)\n",
        "\n",
        "\"\"\"### Tips\n",
        "- Keep CSV column names consistent (`year`, `value`) or adjust in the manifest `year_col`/`value_col`.\n",
        "- For normative caps/targets (e.g., WHO AQG, EU noise, canopy %, cycling %, recycling %), set `min_cap`/`max_cap` in metadata.\n",
        "- To add multiple cities, include a `city` column in each CSV and group by `(year, city, pillar)` similarly.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6a0ae8f",
      "metadata": {
        "id": "d6a0ae8f"
      },
      "source": [
        "# 3. Amsterdam District Processing (from manifest)\n",
        "\n",
        "This section reads the `values_manifest_github` file, loads each indicator Excel file\n",
        "with columns for year, district (`name`) and value, and builds a combined dataframe\n",
        "of indicators per district and year.\n",
        "\n",
        "The result is two dataframes:\n",
        "\n",
        "- `district_raw`  — wide table of raw indicator values per district and year  \n",
        "- `district_scores` — a simple illustrative RCI-like score per district and year  \n",
        "\n",
        "In your final version, you can replace the dummy scoring here with your full RCI logic,\n",
        "using the metadata file to map indicators to pillars and apply weights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5bc565e",
      "metadata": {
        "id": "c5bc565e"
      },
      "outputs": [],
      "source": [
        "\n",
        "from functools import reduce\n",
        "\n",
        "# Try to load manifest (xlsx preferred, fallback csv)\n",
        "manifest_path_xlsx = os.path.join(\"manifests\", \"values_manifest_github.xlsx\")\n",
        "manifest_path_csv  = os.path.join(\"manifests\", \"values_manifest_github.csv\")\n",
        "\n",
        "if os.path.exists(manifest_path_xlsx):\n",
        "    manifest = pd.read_excel(manifest_path_xlsx)\n",
        "elif os.path.exists(manifest_path_csv):\n",
        "    manifest = pd.read_csv(manifest_path_csv)\n",
        "else:\n",
        "    raise FileNotFoundError(\"values_manifest_github.xlsx or .csv not found in manifests/\")\n",
        "\n",
        "print(\"Loaded manifest with\", len(manifest), \"indicators.\")\n",
        "\n",
        "indicator_tables = []\n",
        "\n",
        "for _, row in manifest.iterrows():\n",
        "    indicator = row[\"indicator\"]\n",
        "    relpath = row[\"relpath\"]\n",
        "    year_col = row[\"year_col\"]\n",
        "    parish_col = row[\"parish_col\"]\n",
        "    value_col = row[\"value_col\"]\n",
        "\n",
        "    fp = os.path.join(\"data\", relpath)\n",
        "    if not os.path.exists(fp):\n",
        "        print(\"Warning: file not found for indicator\", indicator, \"->\", fp)\n",
        "        continue\n",
        "\n",
        "    if fp.lower().endswith((\".xlsx\", \".xls\")):\n",
        "        df = pd.read_excel(fp)\n",
        "    else:\n",
        "        df = pd.read_csv(fp)\n",
        "\n",
        "    sub = df[[year_col, parish_col, value_col]].copy()\n",
        "    sub.columns = [\"year\", \"district\", indicator]\n",
        "    indicator_tables.append(sub)\n",
        "\n",
        "if not indicator_tables:\n",
        "    raise RuntimeError(\"No indicator tables were loaded. Check manifest and data paths.\")\n",
        "\n",
        "district_raw = reduce(\n",
        "    lambda left, right: pd.merge(left, right, on=[\"district\", \"year\"], how=\"outer\"),\n",
        "    indicator_tables\n",
        ")\n",
        "\n",
        "print(\"district_raw shape:\", district_raw.shape)\n",
        "district_raw.to_csv(os.path.join(OUTPUT_DIR, \"district_raw_indicators.csv\"), index=False)\n",
        "\n",
        "# --- Simple illustrative scoring (to be replaced by full RCI logic) ---\n",
        "value_cols = [c for c in district_raw.columns if c not in [\"district\", \"year\"]]\n",
        "norm = district_raw.copy()\n",
        "\n",
        "for col in value_cols:\n",
        "    col_min = norm[col].min()\n",
        "    col_max = norm[col].max()\n",
        "    if pd.isna(col_min) or pd.isna(col_max) or col_max == col_min:\n",
        "        norm[col] = 0.0\n",
        "    else:\n",
        "        norm[col] = (norm[col] - col_min) / (col_max - col_min)\n",
        "\n",
        "# For illustration, treat all indicators equally and compute a simple average\n",
        "norm[\"RCI_overall\"] = norm[value_cols].mean(axis=1)\n",
        "\n",
        "# For now, copy overall into the four pillars (placeholder structure)\n",
        "norm[\"RCI_ecological\"] = norm[\"RCI_overall\"]\n",
        "norm[\"RCI_social\"] = norm[\"RCI_overall\"]\n",
        "norm[\"RCI_economic\"] = norm[\"RCI_overall\"]\n",
        "norm[\"RCI_political\"] = norm[\"RCI_overall\"]\n",
        "\n",
        "district_scores = norm[[\"district\", \"year\",\n",
        "                        \"RCI_overall\",\n",
        "                        \"RCI_ecological\",\n",
        "                        \"RCI_social\",\n",
        "                        \"RCI_economic\",\n",
        "                        \"RCI_political\"]].copy()\n",
        "\n",
        "district_scores.to_csv(os.path.join(OUTPUT_DIR, \"district_scores.csv\"), index=False)\n",
        "print(\"district_scores head:\")\n",
        "print(district_scores.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8954199f",
      "metadata": {
        "id": "8954199f"
      },
      "source": [
        "# 4. Map Visualisation (Amsterdam districts)\n",
        "\n",
        "This section creates an interactive Folium map of Amsterdam, with each district\n",
        "coloured by its overall RCI score. It expects a GeoJSON file such as `geojson_lnglat.json`\n",
        "that contains a polygon for each district with a property (e.g. `Stadsdeel`) matching\n",
        "the `district_scores['district']` values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5dbd67f",
      "metadata": {
        "id": "f5dbd67f"
      },
      "outputs": [],
      "source": [
        "\n",
        "if 'district_scores' not in globals():\n",
        "    district_scores = pd.read_csv(os.path.join(OUTPUT_DIR, \"district_scores.csv\"))\n",
        "\n",
        "geojson_path = \"geojson_lnglat.json\"\n",
        "if not os.path.exists(geojson_path):\n",
        "    print(\"GeoJSON file not found:\", geojson_path)\n",
        "else:\n",
        "    try:\n",
        "        ams_gdf = gpd.read_file(geojson_path)\n",
        "    except Exception as e:\n",
        "        print(\"Error reading GeoJSON:\", e)\n",
        "        ams_gdf = None\n",
        "\n",
        "    if ams_gdf is not None:\n",
        "        # Try to match on 'Stadsdeel' property\n",
        "        key_geo = \"Stadsdeel\" if \"Stadsdeel\" in ams_gdf.columns else \"district\"\n",
        "        merged = ams_gdf.merge(district_scores, left_on=key_geo, right_on=\"district\", how=\"left\")\n",
        "\n",
        "        import matplotlib.cm as cm\n",
        "        import matplotlib.colors as colors\n",
        "\n",
        "        vmin = merged[\"RCI_overall\"].min()\n",
        "        vmax = merged[\"RCI_overall\"].max()\n",
        "        cmap = cm.get_cmap(\"plasma\")\n",
        "\n",
        "        def value_to_color(value, vmin, vmax, cmap):\n",
        "            if pd.isna(value):\n",
        "                return \"#cccccc\"\n",
        "            if vmax == vmin:\n",
        "                norm = 0.5\n",
        "            else:\n",
        "                norm = (value - vmin) / (vmax - vmin)\n",
        "            r, g, b, _ = cmap(norm)\n",
        "            return colors.rgb2hex((r, g, b))\n",
        "\n",
        "        import folium\n",
        "        m = folium.Map(location=[52.37, 4.9], zoom_start=11)\n",
        "\n",
        "        for _, row in merged.iterrows():\n",
        "            score = row[\"RCI_overall\"]\n",
        "            color = value_to_color(score, vmin, vmax, cmap)\n",
        "            district_name = row[\"district\"]\n",
        "            geom = row[\"geometry\"]\n",
        "\n",
        "            gj = folium.GeoJson(\n",
        "                geom,\n",
        "                style_function=lambda feature, color=color: {\n",
        "                    \"fillColor\": color,\n",
        "                    \"color\": \"black\",\n",
        "                    \"weight\": 1,\n",
        "                    \"fillOpacity\": 0.7,\n",
        "                },\n",
        "                tooltip=folium.Tooltip(\n",
        "                    f\"<b>District:</b> {district_name}<br><b>RCI overall:</b> {score:.3f}\"\n",
        "                    if pd.notna(score)\n",
        "                    else f\"<b>District:</b> {district_name}<br>No RCI value\"\n",
        "                ),\n",
        "            )\n",
        "            gj.add_to(m)\n",
        "\n",
        "        out_map = os.path.join(MAPS_DIR, \"RCI_Amsterdam_district_map.html\")\n",
        "        m.save(out_map)\n",
        "        print(\"Saved map to:\", out_map)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddb96433",
      "metadata": {
        "id": "ddb96433"
      },
      "source": [
        "# 5. Histogram Generation per District\n",
        "\n",
        "This section generates a bar chart for each district, showing the four RCI dimensions:\n",
        "ecological, social, economic and political."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c75220c0",
      "metadata": {
        "id": "c75220c0"
      },
      "outputs": [],
      "source": [
        "\n",
        "if 'district_scores' not in globals():\n",
        "    district_scores = pd.read_csv(os.path.join(OUTPUT_DIR, \"district_scores.csv\"))\n",
        "\n",
        "for district, group in district_scores.groupby(\"district\"):\n",
        "    latest = group.sort_values(\"year\").iloc[-1]\n",
        "    categories = [\"RCI_ecological\", \"RCI_social\", \"RCI_economic\", \"RCI_political\"]\n",
        "    values = [latest[c] for c in categories]\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    bars = plt.bar([\"Ecological\", \"Social\", \"Economic\", \"Political\"], values,\n",
        "                   color=[\"#2b83ba\", \"#abdda4\", \"#fdae61\", \"#d7191c\"])\n",
        "    plt.title(f\"RCI by dimension – {district}\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    ymax = max(values) if len(values) else 1\n",
        "    plt.ylim(0, ymax * 1.1 if ymax > 0 else 1)\n",
        "\n",
        "    for bar, val in zip(bars, values):\n",
        "        plt.text(bar.get_x() + bar.get_width() / 2,\n",
        "                 bar.get_height(),\n",
        "                 f\"{val:.2f}\",\n",
        "                 ha=\"center\", va=\"bottom\", fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    fname = os.path.join(HIST_DIR, f\"RCI_dimensions_{district.replace(' ', '_')}.png\")\n",
        "    plt.savefig(fname, dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "print(\"Saved histograms to:\", HIST_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dad263a9",
      "metadata": {
        "id": "dad263a9"
      },
      "source": [
        "# 6. Radar Charts per District\n",
        "\n",
        "This section generates radar (spider) charts for each district, using the four RCI\n",
        "dimensions as axes. Charts are saved in the `RCI_outputs/radar/` folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3993b5e",
      "metadata": {
        "id": "c3993b5e"
      },
      "outputs": [],
      "source": [
        "\n",
        "os.makedirs(RADAR_DIR, exist_ok=True)\n",
        "\n",
        "if 'district_scores' not in globals():\n",
        "    district_scores = pd.read_csv(os.path.join(OUTPUT_DIR, \"district_scores.csv\"))\n",
        "\n",
        "def radar_chart(row):\n",
        "    labels = [\"Ecological\", \"Social\", \"Economic\", \"Political\"]\n",
        "    values = [row[\"RCI_ecological\"], row[\"RCI_social\"], row[\"RCI_economic\"], row[\"RCI_political\"]]\n",
        "    angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False)\n",
        "    values_c = np.concatenate((values, [values[0]]))\n",
        "    angles_c = np.concatenate((angles, [angles[0]]))\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    ax = plt.subplot(111, polar=True)\n",
        "    ax.plot(angles_c, values_c, linewidth=2)\n",
        "    ax.fill(angles_c, values_c, alpha=0.25)\n",
        "    ax.set_xticks(angles)\n",
        "    ax.set_xticklabels(labels)\n",
        "    plt.title(f\"RCI radar – {row['district']}\")\n",
        "    out = os.path.join(RADAR_DIR, f\"RCI_radar_{row['district'].replace(' ', '_')}.png\")\n",
        "    plt.savefig(out, dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "latest_scores = district_scores.sort_values(\"year\").groupby(\"district\").tail(1)\n",
        "latest_scores.apply(radar_chart, axis=1)\n",
        "\n",
        "print(\"Radar charts saved to:\", RADAR_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af88a49f",
      "metadata": {
        "id": "af88a49f"
      },
      "source": [
        "# 7. Correlation Matrix of Indicators\n",
        "\n",
        "This section computes a correlation matrix over all numeric indicator columns in\n",
        "`district_raw` and displays a heatmap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1cd9a79",
      "metadata": {
        "id": "d1cd9a79"
      },
      "outputs": [],
      "source": [
        "\n",
        "if 'district_raw' not in globals():\n",
        "    district_raw = pd.read_csv(os.path.join(OUTPUT_DIR, \"district_raw_indicators.csv\"))\n",
        "\n",
        "num_cols = [c for c in district_raw.columns if c not in [\"district\", \"year\"]]\n",
        "corr = district_raw[num_cols].corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr, cmap=\"coolwarm\", center=0)\n",
        "plt.title(\"Correlation matrix of indicators (district-level)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f8667a3",
      "metadata": {
        "id": "5f8667a3"
      },
      "source": [
        "# 8. Scenario Engine (one-step)\n",
        "\n",
        "This section defines a simple scenario engine that perturbs selected indicators by\n",
        "percentage changes and recomputes a new `district_raw` and `district_scores` for each scenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2637d3b1",
      "metadata": {
        "id": "2637d3b1"
      },
      "outputs": [],
      "source": [
        "\n",
        "def run_scenario(data, scenario_dict):\n",
        "    new_data = data.copy()\n",
        "    for indicator, change in scenario_dict.items():\n",
        "        if indicator in new_data.columns:\n",
        "            new_data[indicator] = new_data[indicator] * (1 + change)\n",
        "    return new_data\n",
        "\n",
        "# Example scenarios (adapt these names and indicators to your reality)\n",
        "scenarios = {\n",
        "    \"LOW_CARBON\": {\"env_indicator_toy\": -0.10},\n",
        "    \"SOCIAL_EQUITY\": {\"soc_indicator_toy\": 0.15},\n",
        "}\n",
        "\n",
        "if 'district_raw' not in globals():\n",
        "    district_raw = pd.read_csv(os.path.join(OUTPUT_DIR, \"district_raw_indicators.csv\"))\n",
        "\n",
        "for name, sc in scenarios.items():\n",
        "    scenario_raw = run_scenario(district_raw, sc)\n",
        "    # Recompute simple RCI scores (placeholder) for the scenario\n",
        "    value_cols = [c for c in scenario_raw.columns if c not in [\"district\", \"year\"]]\n",
        "    norm_s = scenario_raw.copy()\n",
        "    for col in value_cols:\n",
        "        col_min = norm_s[col].min()\n",
        "        col_max = norm_s[col].max()\n",
        "        if pd.isna(col_min) or pd.isna(col_max) or col_max == col_min:\n",
        "            norm_s[col] = 0.0\n",
        "        else:\n",
        "            norm_s[col] = (norm_s[col] - col_min) / (col_max - col_min)\n",
        "    norm_s[\"RCI_overall\"] = norm_s[value_cols].mean(axis=1)\n",
        "    norm_s[\"RCI_ecological\"] = norm_s[\"RCI_overall\"]\n",
        "    norm_s[\"RCI_social\"] = norm_s[\"RCI_overall\"]\n",
        "    norm_s[\"RCI_economic\"] = norm_s[\"RCI_overall\"]\n",
        "    norm_s[\"RCI_political\"] = norm_s[\"RCI_overall\"]\n",
        "\n",
        "    scenario_scores = norm_s[[\"district\", \"year\",\n",
        "                              \"RCI_overall\",\n",
        "                              \"RCI_ecological\",\n",
        "                              \"RCI_social\",\n",
        "                              \"RCI_economic\",\n",
        "                              \"RCI_political\"]].copy()\n",
        "    out_csv = os.path.join(SCENARIO_DIR, f\"district_scores_{name}.csv\")\n",
        "    scenario_scores.to_csv(out_csv, index=False)\n",
        "    print(\"Saved scenario scores:\", out_csv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1284a12a",
      "metadata": {
        "id": "1284a12a"
      },
      "source": [
        "# 9. Time-Series Scenario Engine\n",
        "\n",
        "This section creates a simple time-series scenario by applying the same percentage changes\n",
        "across future time steps (e.g., 2030, 2040, 2050) starting from a base year."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15cbfb07",
      "metadata": {
        "id": "15cbfb07"
      },
      "outputs": [],
      "source": [
        "\n",
        "def run_time_series_scenario(df, scenario_changes, years=[2020, 2030, 2040, 2050]):\n",
        "    # Assume df contains a single base year already\n",
        "    base_year = df['year'].min()\n",
        "    base = df[df['year'] == base_year].copy()\n",
        "    frames = []\n",
        "    for i, year in enumerate(years):\n",
        "        temp = base.copy()\n",
        "        for indicator, change in scenario_changes.items():\n",
        "            if indicator in temp.columns:\n",
        "                factor = (1 + change) ** i\n",
        "                temp[indicator] = temp[indicator] * factor\n",
        "        temp[\"year\"] = year\n",
        "        frames.append(temp)\n",
        "    return pd.concat(frames, ignore_index=True)\n",
        "\n",
        "# Example story for time-series (use one of the indicators present)\n",
        "time_scenario = {\"env_indicator_toy\": 0.03}\n",
        "\n",
        "ts_raw = run_time_series_scenario(district_raw, time_scenario)\n",
        "ts_raw.to_csv(os.path.join(SCENARIO_DIR, \"district_raw_time_series.csv\"), index=False)\n",
        "print(\"Saved time-series raw indicators for scenario to:\", os.path.join(SCENARIO_DIR, \"district_raw_time_series.csv\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c7feec0",
      "metadata": {
        "id": "0c7feec0"
      },
      "source": [
        "# 10. Story-Based Scenarios\n",
        "\n",
        "This section defines narrative scenarios (e.g., 'Green Transition', 'Climate Shock') and\n",
        "maps them to indicator changes using the `run_scenario` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0723ae0",
      "metadata": {
        "id": "d0723ae0"
      },
      "outputs": [],
      "source": [
        "\n",
        "stories = {\n",
        "    \"Green_Transition\": {\"env_indicator_toy\": 0.10},\n",
        "    \"Climate_Shock\": {\"eco_indicator_toy\": -0.05},\n",
        "    \"Governance_Reform\": {\"pol_indicator_toy\": 0.15},\n",
        "}\n",
        "\n",
        "for story, changes in stories.items():\n",
        "    out_raw = run_scenario(district_raw, changes)\n",
        "    out_path = os.path.join(SCENARIO_DIR, f\"district_raw_story_{story}.csv\")\n",
        "    out_raw.to_csv(out_path, index=False)\n",
        "    print(\"Saved story-based raw indicators:\", out_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "705be546",
      "metadata": {
        "id": "705be546"
      },
      "source": [
        "# 11. Plotly Dashboard Export (static for GitHub Pages)\n",
        "\n",
        "This section builds a static HTML dashboard in `docs/index.html` using Plotly,\n",
        "so that it can be served by GitHub Pages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38c4be04",
      "metadata": {
        "id": "38c4be04"
      },
      "outputs": [],
      "source": [
        "\n",
        "os.makedirs(\"docs\", exist_ok=True)\n",
        "\n",
        "if 'district_scores' not in globals():\n",
        "    district_scores = pd.read_csv(os.path.join(OUTPUT_DIR, \"district_scores.csv\"))\n",
        "\n",
        "# Use latest year per district\n",
        "latest_scores = district_scores.sort_values(\"year\").groupby(\"district\").tail(1)\n",
        "\n",
        "try:\n",
        "    import plotly.express as px\n",
        "except ImportError:\n",
        "    raise ImportError(\"plotly is required for this section. Install it with `pip install plotly`.\")\n",
        "\n",
        "fig_bar = px.bar(\n",
        "    latest_scores,\n",
        "    x=\"district\",\n",
        "    y=\"RCI_overall\",\n",
        "    title=\"Overall Regenerative Capacity Index by Amsterdam District\",\n",
        "    labels={\"district\": \"District\", \"RCI_overall\": \"RCI overall score\"},\n",
        ")\n",
        "\n",
        "fig_scatter = px.scatter(\n",
        "    latest_scores,\n",
        "    x=\"RCI_ecological\",\n",
        "    y=\"RCI_social\",\n",
        "    color=\"RCI_overall\",\n",
        "    hover_name=\"district\",\n",
        "    title=\"Ecological vs Social RCI scores by district\",\n",
        "    labels={\"RCI_ecological\": \"Ecological score\", \"RCI_social\": \"Social score\"},\n",
        "    color_continuous_scale=\"Viridis\",\n",
        ")\n",
        "\n",
        "html_parts = []\n",
        "html_parts.append(\"<html><head><title>RCI Amsterdam Dashboard</title></head><body>\")\n",
        "html_parts.append(\"<h1>Regenerative Capacity Index – Amsterdam Dashboard</h1>\")\n",
        "\n",
        "html_parts.append(\"<h2>Overall RCI by District</h2>\")\n",
        "html_parts.append(fig_bar.to_html(full_html=False, include_plotlyjs=\"cdn\"))\n",
        "\n",
        "html_parts.append(\"<h2>Ecological vs Social scores</h2>\")\n",
        "html_parts.append(fig_scatter.to_html(full_html=False, include_plotlyjs=False))\n",
        "\n",
        "html_parts.append(\"</body></html>\")\n",
        "\n",
        "with open(os.path.join(\"docs\", \"index.html\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(html_parts))\n",
        "\n",
        "print(\"Static Plotly dashboard written to docs/index.html\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc2e72e6",
      "metadata": {
        "id": "dc2e72e6"
      },
      "source": [
        "# 12. GitHub Actions Builder (workflow + build script)\n",
        "\n",
        "This section writes a minimal `build_plotly_dashboard.py` script and a GitHub Actions\n",
        "workflow file `deploy.yml` to `.github/workflows/`, which can be used to automatically\n",
        "build and deploy the dashboard to GitHub Pages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a16f0fef",
      "metadata": {
        "id": "a16f0fef"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\".github/workflows\", exist_ok=True)\n",
        "\n",
        "build_script = '''\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import os\n",
        "\n",
        "os.makedirs(\"docs\", exist_ok=True)\n",
        "scores = pd.read_csv(\"RCI_outputs/district_scores.csv\")\n",
        "latest_scores = scores.sort_values(\"year\").groupby(\"district\").tail(1)\n",
        "\n",
        "fig_bar = px.bar(\n",
        "    latest_scores,\n",
        "    x=\"district\",\n",
        "    y=\"RCI_overall\",\n",
        "    title=\"Overall Regenerative Capacity Index by Amsterdam District\",\n",
        "    labels={\"district\": \"District\", \"RCI_overall\": \"RCI overall score\"},\n",
        ")\n",
        "\n",
        "fig_scatter = px.scatter(\n",
        "    latest_scores,\n",
        "    x=\"RCI_ecological\",\n",
        "    y=\"RCI_social\",\n",
        "    color=\"RCI_overall\",\n",
        "    hover_name=\"district\",\n",
        "    title=\"Ecological vs Social RCI scores by district\",\n",
        "    labels={\"RCI_ecological\": \"Ecological score\", \"RCI_social\": \"Social score\"},\n",
        "    color_continuous_scale=\"Viridis\",\n",
        ")\n",
        "\n",
        "html_parts = []\n",
        "html_parts.append(\"<html><head><title>RCI Amsterdam Dashboard</title></head><body>\")\n",
        "html_parts.append(\"<h1>Regenerative Capacity Index – Amsterdam Dashboard</h1>\")\n",
        "html_parts.append(\"<h2>Overall RCI by District</h2>\")\n",
        "html_parts.append(fig_bar.to_html(full_html=False, include_plotlyjs=\"cdn\"))\n",
        "html_parts.append(\"<h2>Ecological vs Social scores</h2>\")\n",
        "html_parts.append(fig_scatter.to_html(full_html=False, include_plotlyjs=False))\n",
        "html_parts.append(\"</body></html>\")\n",
        "\n",
        "with open(os.path.join(\"docs\", \"index.html\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(html_parts))\n",
        "\n",
        "print(\"Dashboard built at docs/index.html\")\n",
        "'''\n",
        "\n",
        "with open(\"build_plotly_dashboard.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(build_script)\n",
        "\n",
        "workflow = '''\n",
        "name: Build and Deploy RCI Dashboard\n",
        "\n",
        "on:\n",
        "  push:\n",
        "    branches: [ main ]\n",
        "  workflow_dispatch:\n",
        "\n",
        "permissions:\n",
        "  contents: read\n",
        "  pages: write\n",
        "  id-token: write\n",
        "\n",
        "jobs:\n",
        "  build:\n",
        "    runs-on: ubuntu-latest\n",
        "    steps:\n",
        "      - name: Checkout repo\n",
        "        uses: actions/checkout@v4\n",
        "\n",
        "      - name: Set up Python\n",
        "        uses: actions/setup-python@v5\n",
        "        with:\n",
        "          python-version: \"3.11\"\n",
        "\n",
        "      - name: Install dependencies\n",
        "        run: |\n",
        "          python -m pip install --upgrade pip\n",
        "          pip install pandas plotly\n",
        "\n",
        "      - name: Build dashboard\n",
        "        run: |\n",
        "          python build_plotly_dashboard.py\n",
        "\n",
        "      - name: Upload artifact\n",
        "        uses: actions/upload-pages-artifact@v3\n",
        "        with:\n",
        "          path: docs\n",
        "\n",
        "  deploy:\n",
        "    runs-on: ubuntu-latest\n",
        "    needs: build\n",
        "    environment:\n",
        "      name: github-pages\n",
        "      url: ${{ steps.deployment.outputs.page_url }}\n",
        "    steps:\n",
        "      - name: Deploy to GitHub Pages\n",
        "        id: deployment\n",
        "        uses: actions/deploy-pages@v4\n",
        "'''\n",
        "\n",
        "with open(\".github/workflows/deploy.yml\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(workflow)\n",
        "\n",
        "print(\"Created build_plotly_dashboard.py and .github/workflows/deploy.yml\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}